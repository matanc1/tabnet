{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T19:00:59.650066Z",
     "start_time": "2020-11-04T19:00:59.626885Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T19:00:49.013068Z",
     "start_time": "2020-11-04T19:00:48.318347Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.tabular.all import * \n",
    "from tabnet.model import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T19:00:49.017743Z",
     "start_time": "2020-11-04T19:00:49.014794Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model creating functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:26.734447Z",
     "start_time": "2020-11-01T18:49:26.730660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TabNetBase.__init__)\n",
    "def TabNetClassifier(head_func, to, **kwargs):\n",
    "    return TabNet(head_func, emb_szs=get_emb_sz(to), n_cont=len(to.cont_names), n_out=to.c, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### self supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:27.600041Z",
     "start_time": "2020-11-01T18:49:27.595711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TabNetBase.__init__)\n",
    "def TabNetSelfSupervised(head_func, to, bs=1024, **kwargs):\n",
    "    n_out = len(get_emb_sz(to)) + len(to.cont_names)\n",
    "    return TabNet(head_func, emb_szs=get_emb_sz(to), n_cont=len(to.cont_names), n_out=n_out, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Self Supervised Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:28.225882Z",
     "start_time": "2020-11-01T18:49:28.222455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _maybe_expand(o): return o[:,None] if o.ndim==1 else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:28.623431Z",
     "start_time": "2020-11-01T18:49:28.615819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class ReadTabBatchIdentity(ItemTransform):\n",
    "    \n",
    "    def __init__(self, to): store_attr()\n",
    "        \n",
    "    def encodes(self, to):\n",
    "        if not to.with_cont: res = (tensor(to.cats).long(),)\n",
    "        else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n",
    "        res = res + res #\n",
    "        if to.device is not None: res = to_device(res, to.device)\n",
    "        return res \n",
    "    \n",
    "    \n",
    "    def decodes(self, o):\n",
    "        o = o[0:2]\n",
    "        o = [_maybe_expand(o_) for o_ in to_np(o) if o_.size != 0]\n",
    "        vals = np.concatenate(o, axis=1)\n",
    "        try: df = pd.DataFrame(vals, columns=self.to.all_col_names)\n",
    "        except: df = pd.DataFrame(vals, columns=self.to.x_names)\n",
    "        to = self.to.new(df)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:29.041178Z",
     "start_time": "2020-11-01T18:49:29.038152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularPandasIdentity(TabularPandas): pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T18:49:29.253245Z",
     "start_time": "2020-11-01T18:49:29.247839Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class TabDataLoaderIdentity(TabDataLoader):\n",
    "    do_item = noops\n",
    "    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n",
    "        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTabBatchIdentity(dataset)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def create_batch(self, b): return self.dataset.iloc[b]\n",
    "\n",
    "TabularPandasIdentity._dl_type = TabDataLoaderIdentity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T22:02:39.432689Z",
     "start_time": "2020-10-31T22:02:39.428421Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def tabular_pandas(df, cat_names, cont_names, y_names, val_pct=0.2, tabular_type=TabularPandas):\n",
    "    splits = RandomSplitter(valid_pct=val_pct)(range_of(df))\n",
    "    to = tabular_type(df, procs=[Categorify, FillMissing,Normalize], cont_names=cont_names, cat_names=cat_names,\n",
    "                           y_names=y_names, splits=splits, y_block=CategoryBlock())\n",
    "    return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T22:02:39.589566Z",
     "start_time": "2020-10-31T22:02:39.584274Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "@delegates(TabNetClassifier)\n",
    "def tabnet_df_classifier(df, cat_names, cont_names, y_names, val_pct, head=linear_head, cbs=[], enc=None, **kwargs):\n",
    "    to = tabular_pandas(df, cat_names, cont_names, y_names, val_pct=val_pct)\n",
    "    dls = to.dataloaders(bs=kwargs['bs'])\n",
    "    model = TabNetClassifier(head, to, **kwargs)\n",
    "    if enc is not None: model.enc = enc\n",
    "    cbs=[SetPrior(), MaskRegularizer(kwargs['lambda_sparse']), *cbs]\n",
    "    return Learner(dls, model, CrossEntropyLossFlat(), cbs=cbs, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T22:02:39.760960Z",
     "start_time": "2020-10-31T22:02:39.755242Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TabNetSelfSupervised)\n",
    "def tabnet_df_self_sup(df, cat_names, cont_names, y_names, val_pct, head=tabnet_decoder, \n",
    "                       loss_func=MaskReconstructionLoss(), cbs=[], curriculum=False, p=0.8, **kwargs):\n",
    "    to = tabular_pandas(df, cat_names, cont_names, y_names, tabular_type=TabularPandasIdentity, val_pct=val_pct)\n",
    "    dls = to.dataloaders(bs=kwargs['bs'])\n",
    "    dls.n_inp = 2\n",
    "    cbs = [SetPrior(), TabularMasking(p=p, curriculum=curriculum), MaskRegularizer(kwargs['lambda_sparse']), *cbs]\n",
    "    model = TabNetSelfSupervised(head, to, **kwargs)\n",
    "    return Learner(dls, model, cbs=cbs, loss_func=loss_func, metrics=[mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T22:21:12.917606Z",
     "start_time": "2020-10-31T22:21:12.909938Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "@delegates(tabnet_df_self_sup)\n",
    "def score_before_after_ss(df, ds_params, val_pct, decoder_head, loss_func, cycle_lr, **kwargs):\n",
    "    print(kwargs)\n",
    "    learn = tabnet_df_classifier(df, **ds_params, val_pct=val_pct, **kwargs)\n",
    "    learn.dls.train.bs = learn.dls.train.n//2 if learn.dls.train.n < learn.dls.bs else learn.dls.bs\n",
    "    learn.fit_one_cycle(*cycle_lr[0])\n",
    "    before = accuracy(*learn.get_preds())\n",
    "    \n",
    "    learn_ss = tabnet_df_self_sup(df, **ds_params, val_pct=0.2, head=decoder_head, loss_func=loss_func,\n",
    "                                  **kwargs)\n",
    "    learn_ss.fit_one_cycle(*cycle_lr[1])\n",
    "    \n",
    "    bs = learn.dls.train.n//2 if learn.dls.train.n < learn.dls.bs else learn.dls.bs\n",
    "    mp = {**kwargs, 'virtual_batch_size':bs}\n",
    "    learn = tabnet_df_classifier(df, **ds_params, val_pct=val_pct, enc=learn_ss.model.enc, **mp)\n",
    "    learn.dls.train.bs = bs\n",
    "    learn.fit_one_cycle(*cycle_lr[2])\n",
    "    after = accuracy(*learn.get_preds())\n",
    "\n",
    "    return (before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T18:13:58.954463Z",
     "start_time": "2020-11-04T18:13:58.951721Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "from pathlib import Path\n",
    "from fastai.tabular.all import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T18:14:03.239515Z",
     "start_time": "2020-11-04T18:14:03.236906Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T18:13:51.455294Z",
     "start_time": "2020-11-04T18:13:51.450962Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "def extract_gzip(file, dest=None):\n",
    "    import gzip\n",
    "    dest = dest or Path(dest)\n",
    "    with gzip.open(file, 'rb') as f_in:\n",
    "        with open(dest / file.stem, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "data_dir = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-04T18:20:35.839Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_forest():\n",
    "    forest_type_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
    "    forest_path = untar_data(forest_type_url, dest=data_dir, extract_func=extract_gzip)\n",
    "    \n",
    "    target = \"Covertype\"\n",
    "\n",
    "    cat_names = [\n",
    "        \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
    "        \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
    "        \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
    "        \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
    "        \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
    "        \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
    "        \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
    "        \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
    "        \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
    "        \"Soil_Type40\"\n",
    "    ]\n",
    "\n",
    "    cont_names = [\n",
    "        \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "        \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "        \"Horizontal_Distance_To_Fire_Points\"\n",
    "    ]\n",
    "\n",
    "    feature_columns = (\n",
    "        cont_names + cat_names + [target])\n",
    "\n",
    "    params = dict(cont_names = cont_names, y_names = target, cat_names = cat_names)\n",
    "    procs=[Categorify, FillMissing, Normalize]\n",
    "    model_params = dict(n_d=64, n_a=64, n_steps=5, virtual_batch_size=512, gamma=1.5, bs=1024*16,\n",
    "                        lambda_sparse=1e-4, momentum=0.7, n_shared_ft_blocks=2, n_independent_ft_blocks=2,\n",
    "                        n_dec_steps=10, p=0.8, curriculum=True)\n",
    "    \n",
    "    df = pd.read_csv(forest_path, header=None, names=feature_columns)\n",
    "\n",
    "    return df, params, procs, model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T18:57:57.011458Z",
     "start_time": "2020-11-04T18:57:57.004078Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_adult():\n",
    "    adult_path = untar_data(URLs.ADULT_SAMPLE)\n",
    "    df = pd.read_csv(adult_path/'adult.csv')\n",
    "    procs=[Categorify, FillMissing, Normalize]\n",
    "    params = dict(cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n",
    "                cont_names = ['age', 'fnlwgt', 'education-num'], y_names='salary')\n",
    "    model_params = dict(n_d=16, n_a=16, lambda_sparse=1e-4, bs=1024*4, \n",
    "                              virtual_batch_size=128, n_steps=5, gamma=1.5, n_shared_ft_blocks=2, n_independent_ft_blocks=2,\n",
    "                        n_dec_steps=10, p=0.8, curriculum=True, momentum=0.98)\n",
    "\n",
    "    return df, params, procs, model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T21:34:52.895864Z",
     "start_time": "2020-11-04T21:34:52.799345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_core.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 04_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted results.ipynb.\n",
      "Converted self_supervision.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
