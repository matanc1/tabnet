{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T20:42:16.334861Z",
     "start_time": "2020-10-17T20:42:16.317321Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a `sparsemax` implementation, taken from [here](https://github.com/dreamquark-ai/tabnet/blob/5df2dd19d9fe10e38f4ba13a4c2d6f9707e3f65d/pytorch_tabnet/sparsemax.py). Article [here](https://arxiv.org/abs/1602.02068v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:40.411557Z",
     "start_time": "2020-10-17T21:00:39.999696Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch\n",
    "from torch import nn\n",
    "from fastai.tabular.all import * \n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:40.619593Z",
     "start_time": "2020-10-17T21:00:40.598617Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _make_ix_like(input, dim=0):\n",
    "    d = input.size(dim)\n",
    "    rho = torch.arange(1, d + 1, device=input.device, dtype=input.dtype)\n",
    "    view = [1] * input.dim()\n",
    "    view[0] = -1\n",
    "    return rho.view(view).transpose(0, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:41.078989Z",
     "start_time": "2020-10-17T21:00:41.053781Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "class SparsemaxFunction(Function):\n",
    "    \"\"\"\n",
    "    An implementation of sparsemax (Martins & Astudillo, 2016). See\n",
    "    :cite:`DBLP:journals/corr/MartinsA16` for detailed description.\n",
    "    By Ben Peters and Vlad Niculae\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, dim=-1):\n",
    "        \"\"\"sparsemax: normalizing sparse transform (a la softmax)\n",
    "        Parameters:\n",
    "            input (Tensor): any shape\n",
    "            dim: dimension along which to apply sparsemax\n",
    "        Returns:\n",
    "            output (Tensor): same shape as input\n",
    "        \"\"\"\n",
    "        ctx.dim = dim\n",
    "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
    "        input -= max_val  # same numerical stability trick as for softmax\n",
    "        tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n",
    "        output = torch.clamp(input - tau, min=0)\n",
    "        ctx.save_for_backward(supp_size, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        supp_size, output = ctx.saved_tensors\n",
    "        dim = ctx.dim\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[output == 0] = 0\n",
    "\n",
    "        v_hat = grad_input.sum(dim=dim) / supp_size.to(output.dtype).squeeze()\n",
    "        v_hat = v_hat.unsqueeze(dim)\n",
    "        grad_input = torch.where(output != 0, grad_input - v_hat, grad_input)\n",
    "        return grad_input, None\n",
    "\n",
    "    @staticmethod\n",
    "    def _threshold_and_support(input, dim=-1):\n",
    "        \"\"\"Sparsemax building block: compute the threshold\n",
    "        Args:\n",
    "            input: any dimension\n",
    "            dim: dimension along which to apply the sparsemax\n",
    "        Returns:\n",
    "            the threshold value\n",
    "        \"\"\"\n",
    "\n",
    "        input_srt, _ = torch.sort(input, descending=True, dim=dim)\n",
    "        input_cumsum = input_srt.cumsum(dim) - 1\n",
    "        rhos = _make_ix_like(input, dim)\n",
    "        support = rhos * input_srt > input_cumsum\n",
    "\n",
    "        support_size = support.sum(dim=dim).unsqueeze(dim)\n",
    "        tau = input_cumsum.gather(dim, support_size - 1)\n",
    "        tau /= support_size.to(input.dtype)\n",
    "        return tau, support_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:41.372100Z",
     "start_time": "2020-10-17T21:00:41.350933Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "sparsemax = SparsemaxFunction.apply\n",
    "\n",
    "\n",
    "class Sparsemax(Module):\n",
    "\n",
    "    def __init__(self, dim=-1):\n",
    "        self.dim = dim\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        return sparsemax(input, self.dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:41.694455Z",
     "start_time": "2020-10-17T21:00:41.672330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4707, -2.2783, -0.2929,  0.4337, -0.6759])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5185, 0.0000, 0.0000, 0.4815, 0.0000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5); print(a)\n",
    "sparsemax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:00:42.015782Z",
     "start_time": "2020-10-17T21:00:41.993985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([-100,2,3,4.0])\n",
    "sparsemax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:04:57.721182Z",
     "start_time": "2020-10-17T21:04:57.699007Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class GBN(Module):\n",
    "    \"\"\"\n",
    "        Ghost Batch Normalization\n",
    "        https://arxiv.org/abs/1705.08741\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.02):\n",
    "        self.input_dim = input_dim\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.bn = BatchNorm(self.input_dim, momentum=momentum, ndim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
    "        res = [self.bn(x_) for x_ in chunks]\n",
    "\n",
    "        return torch.cat(res, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T21:04:58.501742Z",
     "start_time": "2020-10-17T21:04:58.403816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_review_prev_work.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 03_experiments.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
