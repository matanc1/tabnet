{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T19:04:14.173994Z",
     "start_time": "2020-11-04T19:04:14.171455Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from tabnet.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet\n",
    "\n",
    "> A TabNet Implementation with Self Supervision using Curriculum Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rerun the experiments, you can run the `experiment.ipynb` notebook. If you want a different dataset, replace the `load_x` function with the one you want from `utils.py`. The `load` functions take care of downloading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code was written solely in notebooks and \"exported\" to `.py` files using the awesome [nbdev](https://nbdev.fast.ai/) project. \n",
    "\n",
    "The final .py files can be found in the `tabnet` directory, howevery you can see the original implementation and tests in the equivalently named notebook. \n",
    "\n",
    "The final files: \n",
    "1. core.py - implementations of `Sparsemax`, and `Ghost Batch Normalization`\n",
    "1. model.py - Includes all the relevant model classes (encoder, decoders, classifier heads, loss functions, relevant callbacks etc)\n",
    "1. utils.py - Helper functions that help:\n",
    "    * load / download the data & model params \n",
    "    * model builders (putting together encoder, decoder from the models.py module)\n",
    "    * experiment helps - such as `score_before_after_ss` which run the model before and after self supervision and return the final accuracy."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
