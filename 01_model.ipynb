{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:54:57.778260Z",
     "start_time": "2020-10-17T09:54:57.761893Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "#default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:54:59.052610Z",
     "start_time": "2020-10-17T09:54:58.231739Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.tabular.all import * \n",
    "from tabnet.sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:19:33.921679Z",
     "start_time": "2020-10-16T12:19:29.505613Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -e ../../libraries/fastai ../../libraries/fastcore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:55:00.068168Z",
     "start_time": "2020-10-17T09:55:00.062405Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GBN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Ghost Batch Normalization\n",
    "        https://arxiv.org/abs/1705.08741\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.02):\n",
    "        super(GBN, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.bn = BatchNorm(self.input_dim, momentum=momentum, ndim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
    "        res = [self.bn(x_) for x_ in chunks]\n",
    "\n",
    "        return torch.cat(res, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:38.396275Z",
     "start_time": "2020-10-17T09:59:38.381626Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TabNet(Module):\n",
    "    \n",
    "    def __init__(self, emb_szs, n_cont, out_features, n_d, n_a, n_steps, n_shared_ft_blocks=2,\n",
    "                         n_independent_ft_blocks=2, gamma=1.5, virtual_batch_size=128, momentum=0.2):        \n",
    "        store_attr()\n",
    "        \n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_features = self.n_emb + n_cont\n",
    "        \n",
    "        \n",
    "#         intermediate_features = n_d + n_a \n",
    "#         self.shared_ft_blocks = [FeatureTransformerBlock(self.n_features, intermediate_features, virtual_batch_size, \n",
    "#                                                          is_first=True)] + \\\n",
    "#                                 [FeatureTransformerBlock(intermediate_features, intermediate_features, virtual_batch_size,\n",
    "#                                                          is_first=False) for _ in range(n_shared_ft_blocks-1)]\n",
    "        \n",
    "\n",
    "        shared_feat_transform = None\n",
    "        if self.n_shared_ft_blocks > 0: \n",
    "            lst = [nn.Linear(self.n_features, 2*(n_d + n_a), bias=False)] + \\\n",
    "                  [nn.Linear(n_d + n_a, 2*(n_d + n_a), bias=False) for _ in range(self.n_shared_ft_blocks-1)]\n",
    "            shared_feat_transform = torch.nn.ModuleList(lst)\n",
    "        \n",
    "\n",
    "        self.initial_ft = FeatTransformer(self.n_features, n_d+n_a, shared_feat_transform,\n",
    "                                                n_glu_independent=self.n_independent_ft_blocks,\n",
    "                                                virtual_batch_size=self.virtual_batch_size,\n",
    "                                                momentum=momentum)\n",
    "\n",
    "    \n",
    "        \n",
    "        self.initial_bn = BatchNorm(self.n_features, ndim=1)\n",
    "#         self.initial_ft = FeatureTransformer(self.shared_ft_blocks, n_d, n_a, n_independent_ft_blocks, virtual_batch_size)\n",
    "        \n",
    "        self.att_steps = nn.ModuleList([AttentiveTransformer(n_a, self.n_features,virtual_batch_size, momentum) \n",
    "                                            for i in range(self.n_steps)])\n",
    "                \n",
    "        self.ft_steps = nn.ModuleList([FeatTransformer(self.n_features, n_d+n_a, shared_feat_transform,\n",
    "                                                          n_glu_independent=self.n_independent_ft_blocks,\n",
    "                                                          virtual_batch_size=self.virtual_batch_size, momentum=momentum)\n",
    "                                               for _ in range(n_steps)])\n",
    "\n",
    "#         self.ft_steps = nn.ModuleList([FeatureTransformer(self.shared_ft_blocks, n_d, n_a,\n",
    "#                                                           n_independent_ft_blocks, virtual_batch_size) \n",
    "#                                             for i in range(self.n_steps)])\n",
    "        \n",
    "        self.final_fc = nn.Linear(n_d, out_features)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = self._combine_cat_cont(x_cat, x_cont)\n",
    "        \n",
    "        output = 0\n",
    "        x = self.initial_bn(x)\n",
    "        res = self.initial_ft(x)\n",
    "        d, a = res[:,:self.n_d], res[:,self.n_d:]\n",
    "        \n",
    "        prior = torch.ones(self.n_features, device=x_cont.device)\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            M = self.att_steps[i](prior, a)\n",
    "            prior = (self.gamma - M)*prior\n",
    "            res = M * x\n",
    "            res = self.ft_steps[i](res)\n",
    "            d, a = res[:,:self.n_d], res[:,self.n_d:]\n",
    "            output = output + nn.functional.relu(d)\n",
    "        \n",
    "        res = self.final_fc(output)\n",
    "        return res\n",
    "    \n",
    "    def _combine_cat_cont(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "        if self.n_cont != 0:\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:38.814748Z",
     "start_time": "2020-10-17T09:59:38.809969Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentiveTransformer(Module):\n",
    "    \n",
    "    def __init__(self, n_a, in_features, virtual_batch_size, momentum):\n",
    "        store_attr()\n",
    "        self.fc = nn.Linear(n_a, in_features)\n",
    "        self.bn = GBN(in_features, virtual_batch_size, momentum)\n",
    "        self.sparsemax = Sparsemax()\n",
    "        \n",
    "    def forward(self, prior, a):\n",
    "        a = self.fc(a)\n",
    "        a = self.bn(a)\n",
    "        a = prior * a\n",
    "        M = self.sparsemax(a)\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:39.209722Z",
     "start_time": "2020-10-17T09:59:39.193652Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class FeatTransformer(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, shared_layers, n_glu_independent,\n",
    "                 virtual_batch_size=128, momentum=0.02):\n",
    "        super(FeatTransformer, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize a feature transformer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        - input_dim : int\n",
    "            Input size\n",
    "        - output_dim : int\n",
    "            Outpu_size\n",
    "        - n_glu_independant\n",
    "        - shared_blocks : torch.nn.ModuleList\n",
    "            The shared block that should be common to every step\n",
    "        - momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in batch norm\n",
    "        \"\"\"\n",
    "\n",
    "        params = {\n",
    "            'n_glu': n_glu_independent,\n",
    "            'virtual_batch_size': virtual_batch_size,\n",
    "            'momentum': momentum\n",
    "        }\n",
    "\n",
    "        if shared_layers is None:\n",
    "            # no shared layers\n",
    "            self.shared = torch.nn.Identity()\n",
    "            is_first = True\n",
    "        else:\n",
    "            self.shared = GLU_Block(input_dim, output_dim,\n",
    "                                    first=True,\n",
    "                                    shared_layers=shared_layers,\n",
    "                                    n_glu=len(shared_layers),\n",
    "                                    virtual_batch_size=virtual_batch_size,\n",
    "                                    momentum=momentum)\n",
    "            is_first = False\n",
    "\n",
    "        if n_glu_independent == 0:\n",
    "            # no independent layers\n",
    "            self.specifics = torch.nn.Identity()\n",
    "        else:\n",
    "            spec_input_dim = input_dim if is_first else output_dim\n",
    "            self.specifics = GLU_Block(spec_input_dim, output_dim,\n",
    "                                       first=is_first,\n",
    "                                       **params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared(x)\n",
    "        x = self.specifics(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLU_Block(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Independant GLU block, specific to each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, n_glu=2, first=False, shared_layers=None,\n",
    "                 virtual_batch_size=128, momentum=0.02):\n",
    "        super(GLU_Block, self).__init__()\n",
    "        self.first = first\n",
    "        self.shared_layers = shared_layers\n",
    "        self.n_glu = n_glu\n",
    "        self.glu_layers = torch.nn.ModuleList()\n",
    "\n",
    "        params = {\n",
    "            'virtual_batch_size': virtual_batch_size,\n",
    "            'momentum': momentum\n",
    "        }\n",
    "\n",
    "        fc = shared_layers[0] if shared_layers else None\n",
    "        self.glu_layers.append(GLU_Layer(input_dim, output_dim,\n",
    "                                         fc=fc,\n",
    "                                         **params))\n",
    "        for glu_id in range(1, self.n_glu):\n",
    "            fc = shared_layers[glu_id] if shared_layers else None\n",
    "            self.glu_layers.append(GLU_Layer(output_dim, output_dim,\n",
    "                                             fc=fc,\n",
    "                                             **params))\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = torch.sqrt(torch.FloatTensor([0.5]).to(x.device))\n",
    "        if self.first:  # the first layer of the block has no scale multiplication\n",
    "            x = self.glu_layers[0](x)\n",
    "            layers_left = range(1, self.n_glu)\n",
    "        else:\n",
    "            layers_left = range(self.n_glu)\n",
    "\n",
    "        for glu_id in layers_left:\n",
    "            x = torch.add(x, self.glu_layers[glu_id](x))\n",
    "            x = x*scale\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLU_Layer(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, fc=None,\n",
    "                 virtual_batch_size=128, momentum=0.02):\n",
    "        super(GLU_Layer, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        if fc:\n",
    "            self.fc = fc\n",
    "        else:\n",
    "            self.fc = nn.Linear(input_dim, 2*output_dim, bias=False)\n",
    "#         initialize_glu(self.fc, input_dim, 2*output_dim)\n",
    "\n",
    "        self.bn = GBN(2*output_dim, virtual_batch_size=virtual_batch_size,\n",
    "                      momentum=momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        out = torch.mul(x[:, :self.output_dim], torch.sigmoid(x[:, self.output_dim:]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:39.604004Z",
     "start_time": "2020-10-17T09:59:39.601435Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# class FeatureTransformer(Module):\n",
    "    \n",
    "#     def __init__(self, shared_blocks, n_d, n_a, n_independent_ft_blocks, virtual_batch_size):\n",
    "#         store_attr()\n",
    "#         intermediate_features = n_d + n_a\n",
    "#         steps = [FeatureTransformerBlock(intermediate_features, intermediate_features, virtual_batch_size, False) \n",
    "#                              for _ in range(n_independent_ft_blocks)]\n",
    "#         self.steps = nn.Sequential(*[*shared_blocks, *steps])\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         res = self.steps(x)\n",
    "#         d, a = res[:,:self.n_d], res[:,self.n_d:]\n",
    "#         return d, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:39.972322Z",
     "start_time": "2020-10-17T09:59:39.969336Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class FeatureTransformerBlock(Module):\n",
    "#     def __init__(self, in_features, intermediate_features, virtual_batch_size, is_first, norm=math.sqrt(0.5)):\n",
    "#         store_attr()\n",
    "        \n",
    "#         self.block1 = self._create_inner_block(is_first=True)\n",
    "#         self.block2 = self._create_inner_block(is_first=False)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x1 = self.block1(x)\n",
    "#         if not self.is_first: x1 = (x1 + x)*self.norm\n",
    "#         x2 = self.block2(x1)\n",
    "#         x2 = (x2 + x1)*self.norm\n",
    "#         return x2\n",
    "        \n",
    "        \n",
    "#     def _create_inner_block(self, is_first):\n",
    "#         intermediate_features = self.intermediate_features\n",
    "#         in_features = self.in_features if is_first else intermediate_features\n",
    "        \n",
    "#         return nn.Sequential(*[\n",
    "#             nn.Linear(in_features, 2*intermediate_features),\n",
    "#             GBN(2*intermediate_features, self.virtual_batch_size),\n",
    "#             nn.GLU(),\n",
    "#         ])        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:40.307072Z",
     "start_time": "2020-10-17T09:59:40.304500Z"
    }
   },
   "outputs": [],
   "source": [
    "# N = 3\n",
    "# n_features = 32\n",
    "# n_d = n_a = 7 \n",
    "# n_steps = 3\n",
    "# out_features = 10\n",
    "# virtual_batch_size = 5\n",
    "\n",
    "# a = torch.randn((N, n_features))\n",
    "# ft = FeatureTransformerBlock(n_features, n_d+n_a, virtual_batch_size, is_first=True)\n",
    "# test_eq(ft(a).shape, (N, n_d+n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:40.962193Z",
     "start_time": "2020-10-17T09:59:40.820050Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randn((N, n_features))\n",
    "tabnet = TabNet([], n_features, out_features, n_d, n_a, n_steps, virtual_batch_size=virtual_batch_size)\n",
    "test_eq(tabnet(a, a).shape, (N, out_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Forest Cover DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:40.214263Z",
     "start_time": "2020-10-16T13:48:40.211172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:40.668498Z",
     "start_time": "2020-10-16T13:48:40.664283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_gzip(file, dest=None):\n",
    "    import gzip\n",
    "    dest = dest or Path(dest)\n",
    "    with gzip.open(file, 'rb') as f_in:\n",
    "        with open(dest / file.stem, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:41.010547Z",
     "start_time": "2020-10-16T13:48:41.004908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "forest_type_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
    "forest_path = untar_data(forest_type_url, dest=data_dir, extract_func=extract_gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:41.186241Z",
     "start_time": "2020-10-16T13:48:41.180661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = \"Covertype\"\n",
    "\n",
    "cat_names = [\n",
    "    \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
    "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
    "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
    "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
    "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
    "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
    "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
    "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
    "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
    "    \"Soil_Type40\"\n",
    "]\n",
    "\n",
    "cont_names = [\n",
    "    \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\"\n",
    "]\n",
    "\n",
    "feature_columns = (\n",
    "    cont_names + cat_names + [target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:42.546539Z",
     "start_time": "2020-10-16T13:48:41.339728Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(forest_path, header=None, names=feature_columns); df.head()\n",
    "df = df_shrink(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:44.304191Z",
     "start_time": "2020-10-16T13:48:42.548321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "procs = [Categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter(0.05)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:48:46.338677Z",
     "start_time": "2020-10-16T13:48:44.306260Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs, cat_names, cont_names, y_names=target, y_block = CategoryBlock(), splits=splits)\n",
    "dls = to.dataloaders(bs=64*64*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T14:24:55.037584Z",
     "start_time": "2020-10-16T14:24:54.987223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = TabNet(get_emb_sz(to), len(to.cont_names), dls.c, n_d=64, n_a=64, n_steps=5, virtual_batch_size=256)\n",
    "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
    "learn = Learner(dls, model, CrossEntropyLossFlat(), opt_func=opt_func, lr=3e-2, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:10:19.659951Z",
     "start_time": "2020-10-16T14:25:00.453843Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Poker Hand DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:30:58.644206Z",
     "start_time": "2020-10-16T16:30:58.641154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = Path.home().joinpath('data/tabnet/poker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:30:58.868973Z",
     "start_time": "2020-10-16T16:30:58.835197Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   4   9   2   1   2   2   4   7   2   8     0\n",
       "1   1   4   3   6   1  12   3  11   2   7     0\n",
       "2   1  11   4   1   3   7   4  11   2   1     2\n",
       "3   2   9   2   4   3   6   1   9   4   9     3\n",
       "4   1   8   2   4   2  11   2   2   2   1     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(BASE_DIR.joinpath('train.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:11:23.692614Z",
     "start_time": "2020-10-16T15:11:23.689302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_names = ['S1', 'S2', 'S3', 'S4', 'S5', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
    "cont_names = []\n",
    "target = ['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:11:28.174284Z",
     "start_time": "2020-10-16T15:11:28.067758Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "procs = [Categorify, Normalize]\n",
    "splits = RandomSplitter(0.05)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:11:32.914397Z",
     "start_time": "2020-10-16T15:11:32.856131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs, cat_names, cont_names, y_names=target, y_block = CategoryBlock(), splits=splits)\n",
    "dls = to.dataloaders(bs=64*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:22:56.925831Z",
     "start_time": "2020-10-17T09:22:56.914990Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TabNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ac78742a1f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = TabNet(get_emb_sz(to), len(to.cont_names), dls.c, n_d=16, n_a=16, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     n_steps=5, virtual_batch_size=256, gamma=1.5)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TabNet' is not defined"
     ]
    }
   ],
   "source": [
    "model = TabNet(get_emb_sz(to), len(to.cont_names), dls.c, n_d=16, n_a=16, \n",
    "                    n_steps=5, virtual_batch_size=256, gamma=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:11:48.874409Z",
     "start_time": "2020-10-16T15:11:48.869793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt_func = partial(Adam, eps=1e-5)\n",
    "learn = Learner(dls, model, CrossEntropyLossFlat(), opt_func=opt_func, lr=3e-2, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T15:14:57.291027Z",
     "start_time": "2020-10-16T15:12:00.643932Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:43.612802Z",
     "start_time": "2020-10-17T09:59:43.536677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(adult_path/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:44.554554Z",
     "start_time": "2020-10-17T09:59:44.354889Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df))\n",
    "to = TabularPandas(df, procs=[Categorify, FillMissing,Normalize],\n",
    "                   cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n",
    "                   cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "                   y_names='salary',\n",
    "                   splits=splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:47.297744Z",
     "start_time": "2020-10-17T09:59:45.045215Z"
    }
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:47.315233Z",
     "start_time": "2020-10-17T09:59:47.299589Z"
    }
   },
   "outputs": [],
   "source": [
    "model = TabNet(get_emb_sz(to), len(to.cont_names), dls.c, n_d=16, n_a=16, \n",
    "                    n_steps=5, virtual_batch_size=256, gamma=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:48.106306Z",
     "start_time": "2020-10-17T09:59:48.101479Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_func = partial(Adam, eps=1e-5)\n",
    "learn = Learner(dls, model, CrossEntropyLossFlat(), opt_func=opt_func, lr=3e-2, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T09:59:55.562808Z",
     "start_time": "2020-10-17T09:59:49.055552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.15848932266235352, lr_steep=0.3630780577659607)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T10:01:38.385154Z",
     "start_time": "2020-10-17T09:59:57.814916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.563679</td>\n",
       "      <td>0.567125</td>\n",
       "      <td>0.761978</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.514371</td>\n",
       "      <td>0.516975</td>\n",
       "      <td>0.779330</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.482633</td>\n",
       "      <td>0.433185</td>\n",
       "      <td>0.791308</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.458221</td>\n",
       "      <td>0.424750</td>\n",
       "      <td>0.801751</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>0.412007</td>\n",
       "      <td>0.802211</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.429047</td>\n",
       "      <td>0.417405</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.418799</td>\n",
       "      <td>0.426190</td>\n",
       "      <td>0.786855</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.413431</td>\n",
       "      <td>0.414170</td>\n",
       "      <td>0.808507</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.409281</td>\n",
       "      <td>0.423823</td>\n",
       "      <td>0.795762</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.406037</td>\n",
       "      <td>0.403161</td>\n",
       "      <td>0.804822</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.404879</td>\n",
       "      <td>0.408704</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.401311</td>\n",
       "      <td>0.404640</td>\n",
       "      <td>0.811271</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.396766</td>\n",
       "      <td>0.401229</td>\n",
       "      <td>0.809429</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.391492</td>\n",
       "      <td>0.388108</td>\n",
       "      <td>0.819564</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.386253</td>\n",
       "      <td>0.390504</td>\n",
       "      <td>0.822482</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.386009</td>\n",
       "      <td>0.396712</td>\n",
       "      <td>0.802672</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.387524</td>\n",
       "      <td>0.397113</td>\n",
       "      <td>0.817107</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.388896</td>\n",
       "      <td>0.397123</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.389517</td>\n",
       "      <td>0.395114</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.407110</td>\n",
       "      <td>0.815264</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.390892</td>\n",
       "      <td>0.389702</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.389067</td>\n",
       "      <td>0.398012</td>\n",
       "      <td>0.806050</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.387532</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.382625</td>\n",
       "      <td>0.381986</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.378097</td>\n",
       "      <td>0.378325</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.374604</td>\n",
       "      <td>0.372708</td>\n",
       "      <td>0.825399</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.371437</td>\n",
       "      <td>0.378645</td>\n",
       "      <td>0.829392</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.369493</td>\n",
       "      <td>0.370241</td>\n",
       "      <td>0.828010</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.367456</td>\n",
       "      <td>0.369865</td>\n",
       "      <td>0.826474</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.365268</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.824171</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.365149</td>\n",
       "      <td>0.367120</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.363777</td>\n",
       "      <td>0.372455</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.361828</td>\n",
       "      <td>0.369458</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.367245</td>\n",
       "      <td>0.395123</td>\n",
       "      <td>0.807893</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.372026</td>\n",
       "      <td>0.822328</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.365725</td>\n",
       "      <td>0.382993</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.364375</td>\n",
       "      <td>0.379685</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.363921</td>\n",
       "      <td>0.366797</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.364572</td>\n",
       "      <td>0.379002</td>\n",
       "      <td>0.822174</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.367338</td>\n",
       "      <td>0.368442</td>\n",
       "      <td>0.821867</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.366158</td>\n",
       "      <td>0.368757</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.364720</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.363476</td>\n",
       "      <td>0.372530</td>\n",
       "      <td>0.822635</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.364135</td>\n",
       "      <td>0.370789</td>\n",
       "      <td>0.822789</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.363806</td>\n",
       "      <td>0.371662</td>\n",
       "      <td>0.822174</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.362307</td>\n",
       "      <td>0.370645</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.363004</td>\n",
       "      <td>0.368890</td>\n",
       "      <td>0.820639</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.361006</td>\n",
       "      <td>0.368526</td>\n",
       "      <td>0.822328</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.359962</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>0.821253</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.360349</td>\n",
       "      <td>0.368209</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.360088</td>\n",
       "      <td>0.371541</td>\n",
       "      <td>0.826321</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.360089</td>\n",
       "      <td>0.367196</td>\n",
       "      <td>0.824017</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.359891</td>\n",
       "      <td>0.365955</td>\n",
       "      <td>0.822482</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.825246</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.358153</td>\n",
       "      <td>0.364731</td>\n",
       "      <td>0.826167</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.357767</td>\n",
       "      <td>0.371576</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.357406</td>\n",
       "      <td>0.369358</td>\n",
       "      <td>0.820332</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.358247</td>\n",
       "      <td>0.367758</td>\n",
       "      <td>0.820485</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.356211</td>\n",
       "      <td>0.365626</td>\n",
       "      <td>0.827088</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>0.373505</td>\n",
       "      <td>0.816953</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.355382</td>\n",
       "      <td>0.365867</td>\n",
       "      <td>0.824939</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.355438</td>\n",
       "      <td>0.366335</td>\n",
       "      <td>0.822328</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.354705</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-994453a49d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/logargs.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/logargs.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlog_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cbs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/fastai/fastai/optimizer.py\u001b[0m in \u001b[0;36madam_step\u001b[0;34m(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mdebias1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mdebias2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr_mom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msqr_mom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqr_avg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdebias2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdebias1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(150, 1e-1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T14:05:21.568216Z",
     "start_time": "2020-10-13T15:50:17.883Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
